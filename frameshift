#!/usr/bin/env python
import subprocess
import argparse
import json
from itertools import product
import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sn
from Bio import Seq
from scipy.stats import fisher_exact
from statsmodels.sandbox.stats.multicomp import fdrcorrection0

parser = argparse.ArgumentParser(description='nominate frameshift promoting pseudoknot motifs')
parser.add_argument('-p', '--pathrepository', required=True,
	help='path to the frameshift repository')
parser.add_argument('-c', '--configfile', required=True,
	help='path to configuration json')
parser.add_argument('-s', '--step', required=True,
	help='step of the pipeline to run')
parser.add_argument('-i', '--inputdata', required=True,
	help='input data for this step of pipeline')
parser.add_argument('-o', '--outputdir', required=True,
	help='directory to write output files')
parser.add_argument('-n', '--numseq', required=False, default=1000,
	help='number of most abundant sequences to analyze')
args = parser.parse_args()

with open(args.configfile) as fh:    
    config = json.load(fh)

def is_revcomp(seq1, seq2):
    answer = True
    nuc_class = {'A' : 'G',
                 'C' : 'T',
                 'G' : 'A',
                 'T' : 'C'}
    bioseq1 = str(Seq.Seq(seq1))
    bioseq2_rc = str(Seq.Seq(seq2).reverse_complement())
    for pos in range(len(bioseq1)):
        nt1 = bioseq1[pos]
        nt2 = bioseq2_rc[pos]
        if nt1 == 'N' or nt2 == 'N':
            continue
        if (nt1 != nt2) and (nt1 not in ['T','G']):
            answer = False
            break
        if (nt1 != nt2) and (nt1 in ['T','G']) and (nt1 != nuc_class[nt2]):
            answer = False
            break
    return answer

def ps_nucleotides_present(seq_list):
    nucleotides = []
    for seq in seq_list:
        for pos in range(len(seq)):
            nucleotides.append('{0}_{1}'.format(pos+1, seq[pos]))
    return list(set(nucleotides))

def gen_psnt_fs(seq_list, ps_nucleotides):
    feature_space = pd.DataFrame(np.zeros((len(seq_list),len(ps_nucleotides))), columns=ps_nucleotides)
    for n in range(len(seq_list)):
        if (n+1) % 500 == 0:
            print 'PSNT {0} / {1}'.format(n + 1, len(seq_list))
        for pos in range(len(seq_list[n])):
            nt = '{0}_{1}'.format(pos + 1, seq_list[n][pos])
            feature_space[nt][n] = 1
    return feature_space

def PK_compatible_present(scaffold, U, S1, L1, S2, L2, L3, D):   
    viable_features = []
    counter = 0
    candidates = list(product(U, S1, L1, S2, L2, L3, D))
    for cand in candidates:
        len_upstream, len_stem1, len_loop1, len_stem2, len_loop2, len_loop3, len_downstream = cand
        total_length = len_upstream + 2*len_stem1 + len_loop1 + 2*len_stem2 + len_loop2 + len_loop3 + len_downstream
        if total_length == len(scaffold):
            seq_stem1a = scaffold[len_upstream : len_upstream+len_stem1]
            seq_stem1b = scaffold[len_upstream+len_stem1+len_loop1+len_stem2+len_loop2 : len_upstream+len_stem1+len_loop1+len_stem2+len_loop2+len_stem1]
            seq_stem2a = scaffold[len_upstream+len_stem1+len_loop1 : len_upstream+len_stem1+len_loop1+len_stem2]
            seq_stem2b = scaffold[len_upstream+len_stem1+len_loop1+len_stem2+len_loop2+len_stem1+len_loop3 : len_upstream+len_stem1+len_loop1+len_stem2+len_loop2+len_stem1+len_loop3+len_stem2]
            if is_revcomp(seq_stem1a, seq_stem1b) and is_revcomp(seq_stem2a, seq_stem2b):
                viable_features.append('{0}|{1}|{2}|{3}|{4}|{5}|{6}'.format(len_upstream,len_stem1,len_loop1,len_stem2,len_loop2,len_loop3,len_downstream))
    return viable_features

def gen_PK_compatibility_fs(seq_list, PK_feature_set):
    num_feats = len(PK_feature_set)
    feature_space = pd.DataFrame(np.zeros((len(seq_list), num_feats+1)),columns=['None']+PK_feature_set)
    row = 0
    for sequence in seq_list:
        if (row + 1) % 500 == 0:
            print 'PK_compatibility {0} / {1}'.format(row + 1, len(seq_list))
        
        compatibility_vector = np.zeros((num_feats+1,))
        counter = 1
        
        winner_PK = {'counter_values' : [0], 'base_pairs' : 0}
        for feat_pk in PK_feature_set:
            len_upstream, len_stem1, len_loop1, len_stem2, len_loop2, len_loop3, len_downstream = tuple(map(int,feat_pk.split("|")))
            seq_stem1a = sequence[len_upstream : len_upstream+len_stem1]
            seq_stem1b = sequence[len_upstream+len_stem1+len_loop1+len_stem2+len_loop2 : len_upstream+len_stem1+len_loop1+len_stem2+len_loop2+len_stem1]
            seq_stem2a = sequence[len_upstream+len_stem1+len_loop1 : len_upstream+len_stem1+len_loop1+len_stem2]
            seq_stem2b = sequence[len_upstream+len_stem1+len_loop1+len_stem2+len_loop2+len_stem1+len_loop3 : len_upstream+len_stem1+len_loop1+len_stem2+len_loop2+len_stem1+len_loop3+len_stem2]
            if is_revcomp(seq_stem1a, seq_stem1b) and is_revcomp(seq_stem2a, seq_stem2b):
                if len(seq_stem1a) + len(seq_stem2a) == winner_PK['base_pairs']:
                    winner_PK['counter_values'].append(counter)
                elif len(seq_stem1a) + len(seq_stem2a) > winner_PK['base_pairs']:
                    winner_PK['counter_values'] = [counter]
                    winner_PK['base_pairs'] = len(seq_stem1a) + len(seq_stem2a)
            counter += 1
        
        if winner_PK['counter_values'] != [0]:
            for feat in winner_PK['counter_values']:
                compatibility_vector[feat] = 1
        else:
            compatibility_vector[0] = 1
            
        feature_space.ix[row, :] = compatibility_vector
        row += 1
    return feature_space

def dot_bracket(u, s1, l1, s2, l2, l3, d):
	db_string = []
	for n in range(int(u)):
		db_string.append('.')
	for n in range(int(s1)):
		db_string.append('(')
	for n in range(int(l1)):
		db_string.append('.')
	for n in range(int(s2)):
		db_string.append('[')
	for n in range(int(l2)):
		db_string.append('.')
	for n in range(int(s1)):
		db_string.append(')')
	for n in range(int(l3)):
		db_string.append('.')
	for n in range(int(s2)):
		db_string.append(']')
	for n in range(int(d)):
		db_string.append('.')
	return ''.join(db_string)


# log_file = open('{0}/frameshift.log'.format(args.outputdir), 'w')

if args.step == "1":
	# log_file.write('##########\nSTEP 1:\n##########\n')
	cmd_1_1 = 'grep -v ">" {0} | grep -v -E "CGAGAT[AG][AG]" | grep -o "{1}" | grep -v "N" > {2}/scaffold_wt.txt'.format(args.inputdata, config['scaffold'], args.outputdir)
	# log_file.write(cmd_1_1 + '\n')
	# subprocess.call(cmd_1_1, shell=True)
	cmd_1_2 = 'sort {0}/scaffold_wt.txt | uniq -c | sort -nr | sed "s/ T/	T/" | sed "s/ C/	C/" | sed "s/ G/	G/" | sed "s/ A/	A/" > {0}/abundances.txt'.format(args.outputdir)
	log_file.write(cmd_1_2 + '\n')
	# subprocess.call(cmd_1_2, shell=True)
	abundances = pd.read_csv('{0}/abundances.txt'.format(args.outputdir), sep='\t', header=None, names=['copy_number','sequence'])
	
	num_sequences_needed = np.where(np.array(np.cumsum(abundances['copy_number']) / abundances['copy_number'].sum()) >= config['top_fraction'])[0][0]
	log_file.write('{0} of the library is contained in the top {1} most abundant sequences'.format(config['top_fraction'], num_sequences_needed) + '\n')
	plt.plot(np.cumsum(abundances['copy_number']) / abundances['copy_number'].sum(), alpha=1.0, label='top {0} contains {1}'.format(num_sequences_needed, config['top_fraction']))
	plt.plot([num_sequences_needed]*int(100*config['top_fraction']), np.arange(0, config['top_fraction'], 0.01), 'k--', alpha=0.3)
	plt.plot(np.arange(1, num_sequences_needed + 1), [config['top_fraction']]*num_sequences_needed, 'k--', alpha=0.3)
	plt.yscale('log')
	plt.xscale('log')
	plt.grid('off')
	plt.title('Percentage of Library in First X Sequences')
	plt.legend(loc='best')
	plt.tight_layout()
	plt.savefig('{0}/library_mass_by_rank.pdf'.format(args.outputdir))


elif args.step == "2":
	# log_file.write('##########\nSTEP 2:\n##########\n')
	abundances = pd.read_csv('{0}'.format(args.inputdata), sep='\t', header=None, names=['copy_number','sequence'])[:int(args.numseq)]
	
	with open('{0}/top_sequences.fasta'.format(args.outputdir), 'w') as top_fasta:
		for i in range(int(args.numseq)):
			top_fasta.write('>{0}\n{1}\n'.format(i, abundances['sequence'][i]))
	cmd_2_1 = '{0}/resources/cdhit/cd-hit-est -i {1}/top_sequences.fasta -o {1}/cd_hit_results -c {2} >/dev/null 2>&1'.format(args.pathrepository, args.outputdir, config['cluster_similarity_threshold'])
	# log_file.write(cmd_2_1 + '\n')
	subprocess.call(cmd_2_1, shell=True)
	subprocess.call(['rm', '{0}/top_sequences.fasta'.format(args.outputdir)])
	K = int(subprocess.check_output(['wc', '-l', '{0}/cd_hit_results'.format(args.outputdir)]).split(args.outputdir)[0].strip()) / 2
	print '{0} clusters detected'.format(K)
	cluster_names = ['cluster_{0}'.format(i) for i in range(K)]
	clustering = pd.DataFrame(np.zeros((int(args.numseq), K)), columns=cluster_names)
	with open('{0}/cd_hit_results.clstr'.format(args.outputdir)) as cd_hit:
		c_num = '0'
		for line in cd_hit:
			if line[0] == '>':
				c_num = line.strip().split()[-1]
			else:
				row = int(line.split('>')[1].split('...')[0])
				clustering['cluster_{0}'.format(c_num)][row] = 1

	seq_list = list(abundances['sequence'])
	scaffold = config['scaffold'].replace('.','N')
	U = range(int(config['PK_compatibility']['U_range'][0]), int(config['PK_compatibility']['U_range'][1]) + 1)
	S1 = range(int(config['PK_compatibility']['S1_range'][0]), int(config['PK_compatibility']['S1_range'][1]) + 1)
	L1 = range(int(config['PK_compatibility']['L1_range'][0]), int(config['PK_compatibility']['L1_range'][1]) + 1)
	S2 = range(int(config['PK_compatibility']['S2_range'][0]), int(config['PK_compatibility']['S2_range'][1]) + 1)
	L2 = range(int(config['PK_compatibility']['L2_range'][0]), int(config['PK_compatibility']['L2_range'][1]) + 1)
	L3 = range(int(config['PK_compatibility']['L3_range'][0]), int(config['PK_compatibility']['L3_range'][1]) + 1)
	D = range(int(config['PK_compatibility']['D_range'][0]), int(config['PK_compatibility']['D_range'][1]) + 1)
	
	feature_names = PK_compatible_present(scaffold, U, S1, L1, S2, L2, L3, D)
	print '{0} pseudoknot geometries being tested for compatibility'.format(len(feature_names))
	featspace_pkcompat = gen_PK_compatibility_fs(seq_list, feature_names)
	total = pd.concat([abundances, featspace_pkcompat, clustering], axis=1, join='inner')
	# total.to_csv('{0}/data_table.tsv'.format(args.outputdir), sep='\t')

	num_factors = 10
	exposures = list(total[cluster_names].sum().order(ascending=False).index)[:num_factors]
	outcomes = list(total[feature_names].sum().order(ascending=False).index)[:num_factors]
	fisher_ORs = []
	fisher_pvals = []

	for e in exposures:
		for o in outcomes:
			ab = len(total[total[e] == 1])
			a = total[total[e] == 1][o].sum()
			b = ab - a
			cd = len(total[total[e] == 0])
			c = total[total[e] == 0][o].sum()
			d = cd - c
			contingency_table = np.array([[a,b],[c,d]])
			odds_ratio, pval = fisher_exact(contingency_table)
			fisher_pvals.append(pval)
			fisher_ORs.append(odds_ratio)

	num_sig_assoc = np.sum(fdrcorrection0(fisher_pvals)[0])
	print 'BH correction for FDR yields {0} significant associations'.format(num_sig_assoc)
	sig_idx = list(np.where(fdrcorrection0(fisher_pvals)[0] == True)[0])
	motif_dict = {}
	motif_dict['Cluster'] = [exposures[int(i / num_factors)] for i in sig_idx]
	motif_dict['Sequence_Mode'] = [total['sequence'][np.where(total[i] == 1)[0][0]] for i in motif_dict['Cluster']]
	motif_dict['PK_feature'] = [outcomes[i % num_factors] for i in sig_idx]
	motif_dict['Dot_Bracket'] = [dot_bracket(*tuple(i.split('|'))) for i in motif_dict['PK_feature']]
	motif_dict['OR_Seq_Struct'] = [fisher_ORs[i] for i in sig_idx]
	motif_dict['pVal_Seq_Struct'] = [fisher_pvals[i] for i in sig_idx]
	motif_dict['qVal_Seq_Struct'] = [fdrcorrection0(fisher_pvals)[1][i] for i in sig_idx]
	motif_table = pd.DataFrame(motif_dict, columns=['Cluster','Sequence_Mode','PK_feature','Dot_Bracket','OR_Seq_Struct','pVal_Seq_Struct','qVal_Seq_Struct'])
	motif_table.sort('OR_Seq_Struct', ascending=False, inplace=True)
	motif_table.index = range(1, 1 + num_sig_assoc)
	motif_table.to_csv('{0}/motif_table.tsv'.format(args.outputdir), index=True, sep='\t')

	for m_id in motif_table.index:
		e = motif_table['Cluster'][m_id]
		o = motif_table['PK_feature'][m_id]
		a_rows = list(total[(total[e] == 1) & (total[o] == 1)].index)
		ab_rows = list(total[total[e] == 1].index)
		ac_rows = list(total[total[o] == 1].index)
		if motif_table['OR_Seq_Struct'][m_id] > 1:
			with open('{0}/a.fasta'.format(args.outputdir), 'w') as fh:
				for row in a_rows:
					fh.write('>seq_id\n{0}\n'.format(total['sequence'][row]))
			subprocess.call('{0}/resources/weblogo/seqlogo -c -F PDF -w 50 -f {1}/a.fasta > {1}/motif_{2}.pdf'.format(args.pathrepository, args.outputdir, m_id), shell=True)
			subprocess.call(['rm', '{0}/a.fasta'.format(args.outputdir)])
			plt.Figure()
			n, bins, patches = plt.hist(np.array(total['copy_number'][ab_rows]), alpha=0.3, color='blue')
			plt.hist(np.array(total['copy_number'][a_rows]), alpha=0.3, color='red', bins=bins)
			plt.tight_layout()
			plt.savefig('{0}/histogram_{1}.pdf'.format(args.outputdir, m_id))
			plt.clf()

# log_file.close()







